{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f06bb0a-17d4-4681-9ad0-51ba7aca189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in d:\\anaconda\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38bcd8d4-52b4-459f-b83d-cca3674bdb09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.12 from \"D:\\Anaconda\\python.exe\"\n  * The NumPy version is: \"1.26.4\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\numpy\\_core\\__init__.py:23\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\numpy\\_core\\multiarray.py:10\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\numpy\\_core\\overrides.py:7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001b[0;32m     11\u001b[0m ARRAY_FUNCTIONS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\numpy\\_core\\__init__.py:49\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m], sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m1\u001b[39m], sys\u001b[38;5;241m.\u001b[39mexecutable,\n\u001b[0;32m     48\u001b[0m         __version__, exc)\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m envkey \u001b[38;5;129;01min\u001b[39;00m env_added:\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.12 from \"D:\\Anaconda\\python.exe\"\n  * The NumPy version is: \"1.26.4\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy._core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[1;31mImportError\u001b[0m: numpy._core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"🌊 WATER TEMPERATURE PREDICTION - EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"📊 Analyzing image-based temperature prediction dataset\")\n",
    "print(\"🔬 Models: Ridge Regression, Random Forest, Gradient Boosting\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd102e-bb18-4efa-a828-285632a124fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3606497-fc93-4555-94ca-0049f5eefc71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_files, temp_values, temperatures\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m image_files, temp_values, temp_dict \u001b[38;5;241m=\u001b[39m load_temperature_data()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📂 Dataset Overview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Total images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(image_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mload_temperature_data\u001b[1;34m(temp_file, img_folder)\u001b[0m\n\u001b[0;32m     13\u001b[0m temperatures[filename] \u001b[38;5;241m=\u001b[39m temp_float\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Check if image exists\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(img_folder, filename)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(img_path):\n\u001b[0;32m     18\u001b[0m     image_files\u001b[38;5;241m.\u001b[39mappend(filename)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def load_temperature_data(temp_file=\"temperatures.txt\", img_folder=\"imgs\"):\n",
    "    \"\"\"Load temperature labels and corresponding images\"\"\"\n",
    "    temperatures = {}\n",
    "    image_files = []\n",
    "    temp_values = []\n",
    "    \n",
    "    # Read temperature file\n",
    "    with open(temp_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if ',' in line:\n",
    "                filename, temp = line.strip().split(', ')\n",
    "                temp_float = float(temp)\n",
    "                temperatures[filename] = temp_float\n",
    "                \n",
    "                # Check if image exists\n",
    "                img_path = os.path.join(img_folder, filename)\n",
    "                if os.path.exists(img_path):\n",
    "                    image_files.append(filename)\n",
    "                    temp_values.append(temp_float)\n",
    "                else:\n",
    "                    print(f\"⚠️  Image not found: {filename}\")\n",
    "    \n",
    "    return image_files, temp_values, temperatures\n",
    "\n",
    "# Load the data\n",
    "image_files, temp_values, temp_dict = load_temperature_data()\n",
    "\n",
    "print(f\"📂 Dataset Overview:\")\n",
    "print(f\"   Total images: {len(image_files)}\")\n",
    "print(f\"   Temperature range: {min(temp_values):.1f}°C - {max(temp_values):.1f}°C\")\n",
    "print(f\"   Mean temperature: {np.mean(temp_values):.1f}°C\")\n",
    "print(f\"   Standard deviation: {np.std(temp_values):.1f}°C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779559cf-fc2e-4b8d-93df-629020415557",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('🌡️ Temperature Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Histogram\n",
    "axes[0,0].hist(temp_values, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].axvline(np.mean(temp_values), color='red', linestyle='--', \n",
    "                  label=f'Mean: {np.mean(temp_values):.1f}°C')\n",
    "axes[0,0].axvline(np.median(temp_values), color='orange', linestyle='--', \n",
    "                  label=f'Median: {np.median(temp_values):.1f}°C')\n",
    "axes[0,0].set_xlabel('Temperature (°C)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].set_title('Temperature Distribution')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "bp = axes[0,1].boxplot(temp_values, patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightcoral')\n",
    "axes[0,1].set_ylabel('Temperature (°C)')\n",
    "axes[0,1].set_title('Temperature Box Plot')\n",
    "axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "# Q-Q plot for normality check\n",
    "from scipy import stats\n",
    "stats.probplot(temp_values, dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot (Normality Check)')\n",
    "axes[1,0].grid(alpha=0.3)\n",
    "\n",
    "# Violin plot\n",
    "axes[1,1].violinplot(temp_values, positions=[1], showmeans=True, showmedians=True)\n",
    "axes[1,1].set_ylabel('Temperature (°C)')\n",
    "axes[1,1].set_title('Temperature Violin Plot')\n",
    "axes[1,1].set_xticks([1])\n",
    "axes[1,1].set_xticklabels(['Temperature'])\n",
    "axes[1,1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(f\"\\n📈 Statistical Summary:\")\n",
    "print(f\"   Count: {len(temp_values)}\")\n",
    "print(f\"   Mean: {np.mean(temp_values):.2f}°C\")\n",
    "print(f\"   Median: {np.median(temp_values):.2f}°C\")\n",
    "print(f\"   Std Dev: {np.std(temp_values):.2f}°C\")\n",
    "print(f\"   Min: {np.min(temp_values):.2f}°C\")\n",
    "print(f\"   Max: {np.max(temp_values):.2f}°C\")\n",
    "print(f\"   Range: {np.max(temp_values) - np.min(temp_values):.2f}°C\")\n",
    "print(f\"   25th Percentile: {np.percentile(temp_values, 25):.2f}°C\")\n",
    "print(f\"   75th Percentile: {np.percentile(temp_values, 75):.2f}°C\")\n",
    "print(f\"   IQR: {np.percentile(temp_values, 75) - np.percentile(temp_values, 25):.2f}°C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb45a2-cce9-4c8d-b8a2-46286e4e1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_enhanced_features(image_path, patch_size=64):\n",
    "    \"\"\"Extract comprehensive features from water images\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width = image_rgb.shape[:2]\n",
    "    \n",
    "    features = []\n",
    "    patch_info = []\n",
    "    \n",
    "    # Multiple patches (center, top, bottom, left, right)\n",
    "    patches = extract_multiple_patches(image_rgb, patch_size)\n",
    "    patch_names = ['center', 'top', 'bottom', 'left', 'right']\n",
    "    \n",
    "    for i, (patch, name) in enumerate(zip(patches, patch_names)):\n",
    "        # RGB statistics\n",
    "        rgb_mean = np.mean(patch, axis=(0, 1))\n",
    "        rgb_std = np.std(patch, axis=(0, 1))\n",
    "        rgb_max = np.max(patch, axis=(0, 1))\n",
    "        rgb_min = np.min(patch, axis=(0, 1))\n",
    "        \n",
    "        features.extend(rgb_mean)      # 3 features\n",
    "        features.extend(rgb_std)       # 3 features  \n",
    "        features.extend(rgb_max)       # 3 features\n",
    "        features.extend(rgb_min)       # 3 features\n",
    "        \n",
    "        # HSV features\n",
    "        patch_hsv = cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)\n",
    "        hsv_mean = np.mean(patch_hsv, axis=(0, 1))\n",
    "        features.extend(hsv_mean)      # 3 features\n",
    "        \n",
    "        # Brightness and contrast\n",
    "        gray_patch = cv2.cvtColor(patch, cv2.COLOR_RGB2GRAY)\n",
    "        brightness = np.mean(gray_patch)\n",
    "        contrast = np.std(gray_patch)\n",
    "        features.extend([brightness, contrast])  # 2 features\n",
    "        \n",
    "        # Store patch info for analysis\n",
    "        patch_info.append({\n",
    "            'name': name,\n",
    "            'rgb_mean': rgb_mean,\n",
    "            'hsv_mean': hsv_mean,\n",
    "            'brightness': brightness,\n",
    "            'contrast': contrast\n",
    "        })\n",
    "    \n",
    "    return np.array(features), patch_info\n",
    "\n",
    "def extract_multiple_patches(image_rgb, patch_size):\n",
    "    \"\"\"Extract patches from different positions\"\"\"\n",
    "    height, width = image_rgb.shape[:2]\n",
    "    half_patch = patch_size // 2\n",
    "    \n",
    "    patches = []\n",
    "    \n",
    "    # Define patch locations\n",
    "    locations = [\n",
    "        (width // 2, height // 2),      # Center\n",
    "        (width // 2, height // 4),      # Top\n",
    "        (width // 2, 3 * height // 4),  # Bottom\n",
    "        (width // 4, height // 2),      # Left\n",
    "        (3 * width // 4, height // 2),  # Right\n",
    "    ]\n",
    "    \n",
    "    for center_x, center_y in locations:\n",
    "        start_y = max(0, center_y - half_patch)\n",
    "        end_y = min(height, center_y + half_patch)\n",
    "        start_x = max(0, center_x - half_patch)\n",
    "        end_x = min(width, center_x + half_patch)\n",
    "        \n",
    "        patch = image_rgb[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        # Resize if needed\n",
    "        if patch.shape[0] < patch_size or patch.shape[1] < patch_size:\n",
    "            patch = cv2.resize(patch, (patch_size, patch_size))\n",
    "            \n",
    "        patches.append(patch)\n",
    "    \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d7f4b-9d61-4708-ab0a-8ffba64e1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔧 Extracting features from all images...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "features_list = []\n",
    "valid_temperatures = []\n",
    "valid_filenames = []\n",
    "patch_analysis = []\n",
    "\n",
    "for i, filename in enumerate(image_files):\n",
    "    img_path = os.path.join(\"imgs\", filename)\n",
    "    \n",
    "    try:\n",
    "        features, patch_info = extract_enhanced_features(img_path)\n",
    "        if features is not None:\n",
    "            features_list.append(features)\n",
    "            valid_temperatures.append(temp_dict[filename])\n",
    "            valid_filenames.append(filename)\n",
    "            patch_analysis.append(patch_info)\n",
    "            \n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"   Processed {i + 1}/{len(image_files)} images...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️  Error processing {filename}: {e}\")\n",
    "\n",
    "# Convert to arrays\n",
    "X = np.array(features_list)\n",
    "y = np.array(valid_temperatures)\n",
    "\n",
    "print(f\"\\n✅ Feature extraction completed!\")\n",
    "print(f\"   Valid samples: {len(X)}\")\n",
    "print(f\"   Feature dimensions: {X.shape}\")\n",
    "print(f\"   Total features per image: {X.shape[1]}\")\n",
    "print(f\"   Features per patch: {X.shape[1] // 5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03a317-53cc-48da-9d2c-85976c3aa071",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎨 RGB COLOR ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Aggregate RGB statistics across all patches\n",
    "rgb_data = []\n",
    "for i, patch_info_list in enumerate(patch_analysis):\n",
    "    temp = valid_temperatures[i]\n",
    "    filename = valid_filenames[i]\n",
    "    \n",
    "    for patch_info in patch_info_list:\n",
    "        rgb_data.append({\n",
    "            'filename': filename,\n",
    "            'temperature': temp,\n",
    "            'patch': patch_info['name'],\n",
    "            'red_mean': patch_info['rgb_mean'][0],\n",
    "            'green_mean': patch_info['rgb_mean'][1],\n",
    "            'blue_mean': patch_info['rgb_mean'][2],\n",
    "            'hue_mean': patch_info['hsv_mean'][0],\n",
    "            'saturation_mean': patch_info['hsv_mean'][1],\n",
    "            'value_mean': patch_info['hsv_mean'][2],\n",
    "            'brightness': patch_info['brightness'],\n",
    "            'contrast': patch_info['contrast']\n",
    "        })\n",
    "\n",
    "rgb_df = pd.DataFrame(rgb_data)\n",
    "\n",
    "# RGB analysis plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('🎨 RGB and Color Feature Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# RGB vs Temperature scatter plots\n",
    "colors = ['red', 'green', 'blue']\n",
    "rgb_channels = ['red_mean', 'green_mean', 'blue_mean']\n",
    "\n",
    "for i, (channel, color) in enumerate(zip(rgb_channels, colors)):\n",
    "    axes[0, i].scatter(rgb_df[channel], rgb_df['temperature'], \n",
    "                      alpha=0.6, color=color, s=30)\n",
    "    axes[0, i].set_xlabel(f'{channel.split(\"_\")[0].title()} Channel Value')\n",
    "    axes[0, i].set_ylabel('Temperature (°C)')\n",
    "    axes[0, i].set_title(f'{channel.split(\"_\")[0].title()} vs Temperature')\n",
    "    axes[0, i].grid(alpha=0.3)\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    corr = rgb_df[channel].corr(rgb_df['temperature'])\n",
    "    axes[0, i].text(0.05, 0.95, f'r = {corr:.3f}', \n",
    "                   transform=axes[0, i].transAxes, \n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# HSV analysis\n",
    "hsv_channels = ['hue_mean', 'saturation_mean', 'value_mean']\n",
    "hsv_colors = ['purple', 'orange', 'brown']\n",
    "\n",
    "for i, (channel, color) in enumerate(zip(hsv_channels, hsv_colors)):\n",
    "    axes[1, i].scatter(rgb_df[channel], rgb_df['temperature'], \n",
    "                      alpha=0.6, color=color, s=30)\n",
    "    axes[1, i].set_xlabel(f'{channel.split(\"_\")[0].title()} Value')\n",
    "    axes[1, i].set_ylabel('Temperature (°C)')\n",
    "    axes[1, i].set_title(f'{channel.split(\"_\")[0].title()} vs Temperature')\n",
    "    axes[1, i].grid(alpha=0.3)\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    corr = rgb_df[channel].corr(rgb_df['temperature'])\n",
    "    axes[1, i].text(0.05, 0.95, f'r = {corr:.3f}', \n",
    "                   transform=axes[1, i].transAxes, \n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cda19-aa4a-45b8-b2fa-8325c7d374ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📊 CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate correlation matrix for key features\n",
    "key_features = ['red_mean', 'green_mean', 'blue_mean', 'hue_mean', \n",
    "               'saturation_mean', 'value_mean', 'brightness', 'contrast', 'temperature']\n",
    "\n",
    "corr_matrix = rgb_df[key_features].corr()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('🔗 Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with temperature\n",
    "temp_corr = corr_matrix['temperature'].abs().sort_values(ascending=False)\n",
    "print(\"🔗 Features most correlated with temperature:\")\n",
    "for feature, corr in temp_corr.items():\n",
    "    if feature != 'temperature':\n",
    "        print(f\"   {feature:<20}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db5f0a-ee2d-41ab-b00a-713dc50bbe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📍 PATCH-WISE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze differences between patches\n",
    "patch_stats = rgb_df.groupby('patch').agg({\n",
    "    'red_mean': ['mean', 'std'],\n",
    "    'green_mean': ['mean', 'std'],\n",
    "    'blue_mean': ['mean', 'std'],\n",
    "    'brightness': ['mean', 'std'],\n",
    "    'contrast': ['mean', 'std'],\n",
    "    'temperature': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(\"📊 Average values by patch location:\")\n",
    "print(patch_stats)\n",
    "\n",
    "# Patch comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('📍 Patch-wise Feature Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Box plots for each RGB channel by patch\n",
    "rgb_channels = ['red_mean', 'green_mean', 'blue_mean']\n",
    "for i, channel in enumerate(rgb_channels):\n",
    "    if i < 3:\n",
    "        row, col = 0, i\n",
    "        sns.boxplot(data=rgb_df, x='patch', y=channel, ax=axes[row, col])\n",
    "        axes[row, col].set_title(f'{channel.split(\"_\")[0].title()} Channel by Patch')\n",
    "        axes[row, col].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Brightness comparison\n",
    "sns.boxplot(data=rgb_df, x='patch', y='brightness', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Brightness by Patch')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Temperature by patch\n",
    "sns.boxplot(data=rgb_df, x='patch', y='temperature', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Temperature by Patch')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6d89b-7027-417e-9e71-031e7a403fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎯 PRELIMINARY FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create feature names for better interpretation\n",
    "feature_names = []\n",
    "patch_names = ['center', 'top', 'bottom', 'left', 'right']\n",
    "feature_types = ['r_mean', 'g_mean', 'b_mean', 'r_std', 'g_std', 'b_std',\n",
    "                'r_max', 'g_max', 'b_max', 'r_min', 'g_min', 'b_min',\n",
    "                'h_mean', 's_mean', 'v_mean', 'brightness', 'contrast']\n",
    "\n",
    "for patch in patch_names:\n",
    "    for feat_type in feature_types:\n",
    "        feature_names.append(f\"{patch}_{feat_type}\")\n",
    "\n",
    "# Quick Random Forest for feature importance\n",
    "rf_temp = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_temp.fit(X, y)\n",
    "\n",
    "# Get feature importance\n",
    "importance_scores = rf_temp.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance_scores\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(20)\n",
    "sns.barplot(data=top_features, y='feature', x='importance', palette='viridis')\n",
    "plt.title('🎯 Top 20 Most Important Features (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"🏆 Top 10 most important features:\")\n",
    "for i, (_, row) in enumerate(importance_df.head(10).iterrows()):\n",
    "    print(f\"   {i+1:2d}. {row['feature']:<25}: {row['importance']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e234018-0e7b-4736-9fae-8159cb288edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🔍 DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for outliers using IQR method\n",
    "Q1 = np.percentile(y, 25)\n",
    "Q3 = np.percentile(y, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = [(i, temp, filename) for i, (temp, filename) in enumerate(zip(y, valid_filenames)) \n",
    "            if temp < lower_bound or temp > upper_bound]\n",
    "\n",
    "print(f\"📊 Data Quality Metrics:\")\n",
    "print(f\"   Total samples: {len(y)}\")\n",
    "print(f\"   Missing values: 0 (handled during loading)\")\n",
    "print(f\"   Outliers detected: {len(outliers)}\")\n",
    "print(f\"   Temperature range: {np.min(y):.1f}°C - {np.max(y):.1f}°C\")\n",
    "print(f\"   IQR bounds: {lower_bound:.1f}°C - {upper_bound:.1f}°C\")\n",
    "\n",
    "if outliers:\n",
    "    print(f\"\\n🚨 Outlier samples:\")\n",
    "    for i, temp, filename in outliers:\n",
    "        print(f\"   {filename}: {temp:.1f}°C\")\n",
    "\n",
    "# Feature scaling analysis\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"\\n📏 Feature Scaling Statistics:\")\n",
    "print(f\"   Original features mean range: {np.mean(X, axis=0).min():.3f} - {np.mean(X, axis=0).max():.3f}\")\n",
    "print(f\"   Original features std range: {np.std(X, axis=0).min():.3f} - {np.std(X, axis=0).max():.3f}\")\n",
    "print(f\"   Scaled features mean: ~{np.mean(X_scaled.mean()):.3f} (should be ~0)\")\n",
    "print(f\"   Scaled features std: ~{np.mean(X_scaled.std()):.3f} (should be ~1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e7c5b-a7bf-4d97-a719-8e6e67e28096",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📋 DATASET CHARACTERISTICS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Image type analysis\n",
    "image_categories = []\n",
    "for filename in valid_filenames:\n",
    "    if filename.startswith('laut_'):\n",
    "        image_categories.append('Sea/Ocean')\n",
    "    elif filename.startswith('IMG_'):\n",
    "        image_categories.append('General Water')\n",
    "    else:\n",
    "        image_categories.append('Mixed/Other')\n",
    "\n",
    "category_counts = pd.Series(image_categories).value_counts()\n",
    "print(f\"📸 Image Categories:\")\n",
    "for category, count in category_counts.items():\n",
    "    percentage = (count / len(image_categories)) * 100\n",
    "    print(f\"   {category:<15}: {count:3d} images ({percentage:5.1f}%)\")\n",
    "\n",
    "# Temperature distribution by category\n",
    "if len(category_counts) > 1:\n",
    "    category_df = pd.DataFrame({\n",
    "        'filename': valid_filenames,\n",
    "        'temperature': y,\n",
    "        'category': image_categories\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n🌡️ Temperature by Category:\")\n",
    "    for category in category_counts.index:\n",
    "        cat_temps = category_df[category_df['category'] == category]['temperature']\n",
    "        print(f\"   {category:<15}: {cat_temps.mean():5.1f}°C ± {cat_temps.std():4.1f}°C\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n📊 ANALYSIS SUMMARY:\")\n",
    "print(f\"   • Dataset size: {len(X)} samples\")\n",
    "print(f\"   • Feature dimensions: {X.shape[1]} features per sample\")\n",
    "print(f\"   • Temperature range: {np.min(y):.1f}°C - {np.max(y):.1f}°C\")\n",
    "print(f\"   • Data quality: {'Good' if len(outliers) < len(y) * 0.1 else 'Needs attention'}\")\n",
    "print(f\"   • Feature extraction: 5 patches × 17 features = 85 total features\")\n",
    "print(f\"   • Ready for model training: ✅\")\n",
    "\n",
    "print(\"\\n🎯 RECOMMENDATIONS FOR MODEL TRAINING:\")\n",
    "print(\"   • Use feature scaling (StandardScaler) for Ridge Regression\")\n",
    "print(\"   • Tree-based models (RF, GB) can handle raw features\")\n",
    "print(\"   • Consider cross-validation due to moderate dataset size\")\n",
    "print(\"   • Monitor for overfitting with tree-based models\")\n",
    "print(\"   • RGB and brightness features show promise for temperature prediction\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📝 EDA COMPLETE - Ready for Model Training!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
